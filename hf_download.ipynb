{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid.\n",
      "Your token has been saved to C:\\Users\\parkm\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "access_token_write = \"xxxxxxxxxxx\"\n",
    "login(token = access_token_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e9cbca55544eadb8294cd6b51688ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0973e48f88074e5793834719c8ee75eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940fa2f0f4fd451dbdb1b18be52452f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e2526c07054f6390fc8c8cacfa9bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6dada553c9406f8360ab34c67ac2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "import joblib\n",
    "\n",
    "REPO_ID = \"meta-llama/Llama-2-7b-hf\"\n",
    "snapshot_download(repo_id=REPO_ID, local_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli delete-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!apt-get -y install -qq aria2\n",
    "\n",
    "!git clone -b v1.7 https://github.com/camenduru/text-generation-webui\n",
    "%cd /content/text-generation-webui\n",
    "!pip install -r requirements.txt\n",
    "!pip install -U gradio==3.28.3\n",
    "\n",
    "!mkdir /content/text-generation-webui/repositories\n",
    "%cd /content/text-generation-webui/repositories\n",
    "!git clone -b v1.2 https://github.com/camenduru/GPTQ-for-LLaMa.git\n",
    "%cd GPTQ-for-LLaMa\n",
    "!python setup_cuda.py install\n",
    "\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/danielpark/ko-llama-2-jindo-7b-instruct-4bit-128g-gptq/blob/main/config.json -d /content/text-generation-webui/models/pyg-13b-4bit-128g -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/danielpark/ko-llama-2-jindo-7b-instruct-4bit-128g-gptq/blob/main/quantize_config.json -d /content/text-generation-webui/models/pyg-13b-4bit-128g -o generation_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/danielpark/ko-llama-2-jindo-7b-instruct-4bit-128g-gptq/blob/main/special_tokens_map.json -d /content/text-generation-webui/models/pyg-13b-4bit-128g -o special_tokens_map.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/danielpark/ko-llama-2-jindo-7b-instruct-4bit-128g-gptq/blob/main/tokenizer.model -d /content/text-generation-webui/models/pyg-13b-4bit-128g -o tokenizer.model\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/danielpark/ko-llama-2-jindo-7b-instruct-4bit-128g-gptq/blob/main/tokenizer_config.json -d /content/text-generation-webui/models/pyg-13b-4bit-128g -o tokenizer_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/danielpark/ko-llama-2-jindo-7b-instruct-4bit-128g-gptq/resolve/main/4bit-128g.safetensors -d /content/text-generation-webui/models/pyg-13b-4bit-128g -o 4bit-128g.safetensors\n",
    "\n",
    "%cd /content/text-generation-webui\n",
    "!python server.py --share --chat --wbits 4 --groupsize 128 --model_type llama"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc",
   "language": "python",
   "name": "cc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
